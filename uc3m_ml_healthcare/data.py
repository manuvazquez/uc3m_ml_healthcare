# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/10_data.ipynb.

# %% auto 0
__all__ = ['make_periodic_dataset']

# %% ../nbs/10_data.ipynb 3
import pathlib
import itertools

from fastcore.utils import patch

import pandas as pd
import numpy as np
import torch
import torch.distributions

# from latent_ode.generate_timeseries import Periodic_1d

# %% ../nbs/10_data.ipynb 4
def make_periodic_dataset(**kwargs) -> tuple[torch.Tensor, torch.Tensor]:
    
    # so that we can use the original code "verbatim" (plus some comments)
    args = types.SimpleNamespace(**kwargs)
    
    # ---------

    n_total_tp = args.timepoints + args.extrap

    # better understood as max_t_extrap = n_total_tp / args.timepoints * args.max_t (you adjust `max_t` if extrapolation is requested)
    # if `args.extrap` is `False`, then this is exactly equal to `n_total_tp` since `n_total_tp = args.timepoints`
    max_t_extrap = args.max_t / args.timepoints * n_total_tp

    distribution = uniform.Uniform(torch.Tensor([0.0]),torch.Tensor([max_t_extrap]))
    time_steps_extrap =  distribution.sample(torch.Size([n_total_tp-1]))[:,0] # last part is just "squeezing"
    time_steps_extrap = torch.cat((torch.Tensor([0.0]), time_steps_extrap)) # 0 is always there
    time_steps_extrap = torch.sort(time_steps_extrap)[0]

    dataset_obj = Periodic_1d( # frequencies are not passed (and henced sampled internally)
        init_freq = None, init_amplitude = 1.,
        final_amplitude = 1., final_freq = None, 
        z0 = 1.)

    dataset = dataset_obj.sample_traj(time_steps_extrap, n_samples = args.n, noise_weight = args.noise_weight)
    
    # ---------
    
    return time_steps_extrap, dataset
