{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab8ade1-d362-46dd-9e16-4cefc3a8eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a695afa-243c-4f3f-b24a-074f9256c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2332089-8b7f-4771-92b5-b3524c9791d0",
   "metadata": {},
   "source": [
    "# train\n",
    "> Some code to ease up training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59825b19-defe-4c3c-af71-161bad51b33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1fe7c-5cdb-45de-bb72-6ae503d7b3e2",
   "metadata": {},
   "source": [
    "A loss function meant to be used with [Latent ODEs for Irregularly-Sampled Time Series](https://github.com/YuliaRubanova/latent_ode)'s `LatentODE`. Some modifications were applied:\n",
    "- a mask is required since the sparse observations are supported\n",
    "- likelihood is averaged over all the trials (rather than added across)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0d907b-cc24-4ddd-a618-0cb7b6ea45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LatentODELoss:\n",
    "    \"A loss function meant to be paired with Rubanova's `LatentODE`\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 noise_std: torch.Tensor, # Standard deviation of the noise assumed when computing the likelihood\n",
    "                 prior: torch.distributions.normal.Normal # Prior distribution for the initial state\n",
    "                ):\n",
    "        \n",
    "        self.noise_std = noise_std\n",
    "        self.prior = prior\n",
    "        \n",
    "        self.mse_loss = nn.MSELoss()\n",
    "        \n",
    "    def __str__(self):\n",
    "        \n",
    "        return f'LatentODELoss with:\\n\\tnoise standard deviation = {self.noise_std}\\n\\tprior: {self.prior}'\n",
    "    \n",
    "    __repr__ = __str__\n",
    "           \n",
    "    def __call__(self,\n",
    "        pred: torch.Tensor, # Predictions [time, trial, batch, feature]\n",
    "        mean: torch.Tensor, # Mean [batch, ...]\n",
    "        std: torch.Tensor, # Standard deviation [batch, ...]\n",
    "        target: torch.Tensor, # Targets [batch, time, feature]\n",
    "        target_mask: torch.BoolTensor, # Targets [batch, time, feature]\n",
    "        kl_weight: float # KL divergence weight on the loss\n",
    "    ) -> tuple[torch.Tensor, dict]: # Loss and some extra info\n",
    "\n",
    "\n",
    "        # -------------- KL divergence\n",
    "        \n",
    "        # the *posterior* (observations have already been processed) distribution of the latent state at the beginning\n",
    "        z0_posterior = torch.distributions.normal.Normal(mean, std)\n",
    "\n",
    "        # [1, batch, latent feature]\n",
    "        kl = torch.distributions.kl.kl_divergence(z0_posterior, self.prior)\n",
    "\n",
    "        kl_average = kl.mean()\n",
    "        \n",
    "        # -------------- likelihood\n",
    "        \n",
    "        # we'd rather have [trial, batch, time, feature]\n",
    "        pred = pred.permute([1, 2, 0, 3])\n",
    "\n",
    "        assert pred.shape[1:] == target.shape\n",
    "\n",
    "        # the distribution of the predictions...\n",
    "        pred_distribution = torch.distributions.normal.Normal(loc=pred, scale=self.noise_std)\n",
    "\n",
    "        # ...is used to compute the likelihood\n",
    "        likelihood = pred_distribution.log_prob(target)\n",
    "\n",
    "        n_samples = len(pred)\n",
    "        \n",
    "        # -------------- MSE\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            mse = self.mse_loss(pred, target.expand((n_samples,) + target.shape))\n",
    "            \n",
    "        # --------------\n",
    "\n",
    "        loss = - (torch.masked_select(likelihood, target_mask).mean() - kl_weight * kl_average)\n",
    "\n",
    "        return loss, dict(kl_average=kl_average, mse=mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15c8300-dc9f-4024-b784-989ddd40530f",
   "metadata": {},
   "source": [
    "The parameters required to.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f890bad4-46bc-4943-b27a-b0375516dd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = torch.distributions.normal.Normal(torch.tensor(0.0), torch.tensor(1.))\n",
    "noise_std = torch.tensor(0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2d238-a097-442e-a6f8-cf88eab1d011",
   "metadata": {},
   "source": [
    "...instantiate the class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e81f3-9a75-4b4c-852e-6aa08c9d967a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentODELoss with:\n",
       "\tnoise standard deviation = 0.009999999776482582\n",
       "\tprior: Normal(loc: 0.0, scale: 1.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func = LatentODELoss(noise_std, prior)\n",
    "loss_func"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb9aea-113e-4082-829f-bcbf40502171",
   "metadata": {},
   "source": [
    "Some random data for testing purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a7fe6a-7c1d-4946-be3c-23b74180ea26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_time_instants = 12\n",
    "n_trials = 3\n",
    "batch_size = 32\n",
    "features_size = 2\n",
    "latent_size = 13\n",
    "\n",
    "pred = torch.randn(n_time_instants, n_trials, batch_size, features_size)\n",
    "mean = torch.randn(1, batch_size, latent_size)\n",
    "std = torch.rand_like(mean)\n",
    "target = torch.randn(batch_size, n_time_instants, features_size)\n",
    "target_mask = (torch.randn_like(target) > 0.).bool()\n",
    "kl_weight = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e7de2e-d596-4475-af9a-b821ccc25e02",
   "metadata": {},
   "source": [
    "The loss function is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9592dba7-4a54-401b-a6c3-9567e27baf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(9830.3252), {'kl_average': tensor(1.2236), 'mse': tensor(2.0446)})"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_func(pred, mean, std, target, target_mask, kl_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48b386-dc36-4c7c-b580-9cb4f7d92808",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.doclinks import nbdev_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cffcf61-50c9-41fd-a47a-04e44ca8f157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nbdev_export('30_train.ipynb')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
